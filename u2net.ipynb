{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13333,"databundleVersionId":862146,"sourceType":"competition"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":25033.471826,"end_time":"2024-11-26T21:41:36.204146","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-11-26T14:44:22.73232","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **1. Imports**","metadata":{"papermill":{"duration":0.006703,"end_time":"2024-11-26T14:44:26.188107","exception":false,"start_time":"2024-11-26T14:44:26.181404","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport os\n!pip install segmentation-models-pytorch --quiet\nimport segmentation_models_pytorch as smp\nfrom tqdm import tqdm\nfrom sklearn.model_selection import KFold\nimport albumentations as A\nfrom albumentations import (Compose, ShiftScaleRotate, Resize, RandomRotate90,\n                            VerticalFlip, HorizontalFlip, OneOf, ElasticTransform,\n                            GridDistortion, OpticalDistortion, CLAHE,\n                            GaussNoise, ISONoise, RandomBrightnessContrast, RandomGamma)\nfrom albumentations.pytorch import ToTensorV2\nfrom torchvision import transforms\nimport time\n!pip install torch-lr-finder\nfrom torch_lr_finder import LRFinder\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-02-14T13:11:52.213444Z","iopub.execute_input":"2025-02-14T13:11:52.213761Z","iopub.status.idle":"2025-02-14T13:12:15.260042Z","shell.execute_reply.started":"2025-02-14T13:11:52.213734Z","shell.execute_reply":"2025-02-14T13:12:15.258903Z"},"papermill":{"duration":41.308914,"end_time":"2024-11-26T14:45:07.504139","exception":false,"start_time":"2024-11-26T14:44:26.195225","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting torch-lr-finder\n  Downloading torch_lr_finder-0.2.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (3.7.5)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (1.26.4)\nRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (2.5.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (4.67.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=0.4.1->torch-lr-finder) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (1.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (2.8.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-lr-finder) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-lr-finder) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-lr-finder) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-lr-finder) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-lr-finder) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-lr-finder) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->torch-lr-finder) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->torch-lr-finder) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-lr-finder) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-lr-finder) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-lr-finder) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-lr-finder) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-lr-finder) (2024.2.0)\nDownloading torch_lr_finder-0.2.2-py3-none-any.whl (12 kB)\nInstalling collected packages: torch-lr-finder\nSuccessfully installed torch-lr-finder-0.2.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# **2. Data Prep**","metadata":{"papermill":{"duration":0.005994,"end_time":"2024-11-26T14:45:07.516699","exception":false,"start_time":"2024-11-26T14:45:07.510705","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**2.1 Load and Process the DataFrame**","metadata":{"papermill":{"duration":0.005929,"end_time":"2024-11-26T14:45:07.528713","exception":false,"start_time":"2024-11-26T14:45:07.522784","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Load the train.csv file\ntrain_df = pd.read_csv('/kaggle/input/understanding_cloud_organization/train.csv')\n\n# Separate Image_Label into ImageId and Label\ntrain_df[['ImageId', 'Label']] = train_df['Image_Label'].str.split('_', expand=True)\ntrain_df = train_df.drop(columns=['Image_Label'])\n\n# Fill missing EncodedPixels with NaN\ntrain_df['EncodedPixels'] = train_df['EncodedPixels'].fillna('')\n\n# Pivot the dataframe to have one row per image\ntrain_df = train_df.pivot(index='ImageId', columns='Label', values='EncodedPixels').reset_index()\n\n# Fill missing values with empty strings\ntrain_df.fillna('', inplace=True)\n\nprint(train_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:15.261561Z","iopub.execute_input":"2025-02-14T13:12:15.261821Z","iopub.status.idle":"2025-02-14T13:12:18.964595Z","shell.execute_reply.started":"2025-02-14T13:12:15.261799Z","shell.execute_reply":"2025-02-14T13:12:18.963748Z"},"papermill":{"duration":4.534141,"end_time":"2024-11-26T14:45:12.068845","exception":false,"start_time":"2024-11-26T14:45:07.534704","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Label      ImageId                                               Fish  \\\n0      0011165.jpg  264918 937 266318 937 267718 937 269118 937 27...   \n1      002be4f.jpg  233813 878 235213 878 236613 878 238010 881 23...   \n2      0031ae9.jpg  3510 690 4910 690 6310 690 7710 690 9110 690 1...   \n3      0035239.jpg                                                      \n4      003994e.jpg  2367966 18 2367985 2 2367993 8 2368002 62 2369...   \n\nLabel                                             Flower  \\\n0      1355565 1002 1356965 1002 1358365 1002 1359765...   \n1      1339279 519 1340679 519 1342079 519 1343479 51...   \n2      2047 703 3447 703 4847 703 6247 703 7647 703 9...   \n3      100812 462 102212 462 103612 462 105012 462 10...   \n4                                                          \n\nLabel                                             Gravel  \\\n0                                                          \n1                                                          \n2                                                          \n3      65400 380 66800 380 68200 380 69600 380 71000 ...   \n4      353317 416 354717 416 356117 416 357517 416 35...   \n\nLabel                                              Sugar  \n0                                                         \n1      67495 350 68895 350 70295 350 71695 350 73095 ...  \n2      658170 388 659570 388 660970 388 662370 388 66...  \n3                                                         \n4      28011 489 29411 489 30811 489 32211 489 33611 ...  \n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"**2.2 Split Data into Training and Validation Sets**","metadata":{"papermill":{"duration":0.006718,"end_time":"2024-11-26T14:45:12.0834","exception":false,"start_time":"2024-11-26T14:45:12.076682","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Initialize the 'fold' column to -1\ntrain_df['fold'] = -1\n\n# Initialize KFold\nkf = KFold(n_splits=9, shuffle=True, random_state=42) ##maybe change THIS                              IMPORTANT\n\n# Assign fold numbers\nfor fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n    train_df.loc[val_idx, 'fold'] = fold\n\n# Now select one fold for validation (e.g., fold 0)\ntrain_data = train_df[train_df['fold'] != 0].reset_index(drop=True)\nval_data = train_df[train_df['fold'] == 0].reset_index(drop=True)\n\n# Verify the split\nprint(f\"Training data size: {len(train_data)}\")\nprint(f\"Validation data size: {len(val_data)}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:18.965923Z","iopub.execute_input":"2025-02-14T13:12:18.966160Z","iopub.status.idle":"2025-02-14T13:12:18.983766Z","shell.execute_reply.started":"2025-02-14T13:12:18.966140Z","shell.execute_reply":"2025-02-14T13:12:18.983032Z"},"papermill":{"duration":0.027458,"end_time":"2024-11-26T14:45:12.117992","exception":false,"start_time":"2024-11-26T14:45:12.090534","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Training data size: 4929\nValidation data size: 617\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **3. Create Custom Dataset**","metadata":{"papermill":{"duration":0.006086,"end_time":"2024-11-26T14:45:12.130328","exception":false,"start_time":"2024-11-26T14:45:12.124242","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class CloudDataset(Dataset):\n    def __init__(self, df, img_dir, mask_dir=None, transform=None, resize_shape=(416, 608), mode='train'):\n        self.df = df\n        self.img_dir = img_dir\n        self.mask_dir = mask_dir\n        self.transform = transform\n        self.resize_shape = resize_shape\n        self.mode = mode  # 'train', 'val', or 'test'\n        self.labels = ['Fish', 'Flower', 'Gravel', 'Sugar']\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        # Get image ID\n        img_id = self.df.iloc[idx]['ImageId']\n        # Load image\n        img_path = os.path.join(self.img_dir, img_id)\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        if self.mode != 'test':\n            # Create mask\n            mask = np.zeros((1400, 2100, 4), dtype=np.float32)\n            for i, label in enumerate(self.labels):\n                rle = self.df.iloc[idx][label]\n                if rle != '':\n                    mask[:, :, i] = rle2mask(rle, (1400, 2100))\n            # Resize image and mask\n            if self.transform:\n                augmented = self.transform(image=image, mask=mask)\n                image = augmented['image']\n                mask = augmented['mask']\n            else:\n                # Resize\n                image = cv2.resize(image, (self.resize_shape[1], self.resize_shape[0]))\n                mask = cv2.resize(mask, (self.resize_shape[1], self.resize_shape[0]))\n            # Transpose to channel-first\n            image = image.transpose(2, 0, 1).astype(np.float32) / 255.0\n            mask = mask.transpose(2, 0, 1).astype(np.float32)\n            return torch.tensor(image), torch.tensor(mask)\n        else:\n            # For test mode\n            if self.transform:\n                augmented = self.transform(image=image)\n                image = augmented['image']\n            else:\n                image = cv2.resize(image, (self.resize_shape[1], self.resize_shape[0]))\n            image = image.transpose(2, 0, 1).astype(np.float32) / 255.0\n            return torch.tensor(image), img_id\n\ndef rle2mask(rle, shape):\n    '''\n    Convert RLE(run length encoding) string to numpy array\n\n    Parameters:\n    rle (str): Run length encoding string\n    shape (tuple): (height, width) of array to return\n\n    Returns:\n    numpy.array: Mask array\n    '''\n    s = rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1  # Convert to zero-based indexing\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape, order='F')  # Reshape to the original shape\n","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:18.985044Z","iopub.execute_input":"2025-02-14T13:12:18.985330Z","iopub.status.idle":"2025-02-14T13:12:19.021753Z","shell.execute_reply.started":"2025-02-14T13:12:18.985296Z","shell.execute_reply":"2025-02-14T13:12:19.020977Z"},"papermill":{"duration":0.020939,"end_time":"2024-11-26T14:45:12.157405","exception":false,"start_time":"2024-11-26T14:45:12.136466","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# **4. Augmentations**","metadata":{"papermill":{"duration":0.006498,"end_time":"2024-11-26T14:45:12.170418","exception":false,"start_time":"2024-11-26T14:45:12.16392","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_transform = Compose([\n    ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=0.6, border_mode=0),\n    OneOf([\n        GridDistortion(p=0.5),\n        OpticalDistortion(p=0.5, distort_limit=0.4, shift_limit=0.5)\n    ], p=0.8),\n    RandomRotate90(p=0.5),\n    VerticalFlip(p=0.5),\n    HorizontalFlip(p=0.5),\n    OneOf([\n         CLAHE(p=0.8),\n        GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n        # GaussianBlur(blur_limit=3, p=0.5),\n        ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.3),\n    ], p=0.8),\n    RandomBrightnessContrast(p=0.8),\n    RandomGamma(p=0.8),\n    Resize(416, 608)\n])\n\nval_transform = Compose([\n    Resize(416, 608),\n])\n","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:19.022631Z","iopub.execute_input":"2025-02-14T13:12:19.022915Z","iopub.status.idle":"2025-02-14T13:12:19.043533Z","shell.execute_reply.started":"2025-02-14T13:12:19.022895Z","shell.execute_reply":"2025-02-14T13:12:19.042882Z"},"papermill":{"duration":0.017289,"end_time":"2024-11-26T14:45:12.193847","exception":false,"start_time":"2024-11-26T14:45:12.176558","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# **5. Dataloaders**","metadata":{"papermill":{"duration":0.006016,"end_time":"2024-11-26T14:45:12.206018","exception":false,"start_time":"2024-11-26T14:45:12.200002","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Paths to your images and masks\ntrain_img_dir = '/kaggle/input/understanding_cloud_organization/train_images'\ntest_img_dir = '/kaggle/input/understanding_cloud_organization/test_images'\n\n# Create datasets\ntrain_dataset = CloudDataset(df=train_data, img_dir=train_img_dir, transform=train_transform)\nval_dataset = CloudDataset(df=val_data, img_dir=train_img_dir, transform=val_transform)\n\n# Create dataloaders\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, pin_memory=True)\n\nprint(len(train_loader))\nprint(len(val_loader))","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:19.044230Z","iopub.execute_input":"2025-02-14T13:12:19.044453Z","iopub.status.idle":"2025-02-14T13:12:19.060760Z","shell.execute_reply.started":"2025-02-14T13:12:19.044411Z","shell.execute_reply":"2025-02-14T13:12:19.059726Z"},"papermill":{"duration":0.014266,"end_time":"2024-11-26T14:45:12.226318","exception":false,"start_time":"2024-11-26T14:45:12.212052","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"2465\n309\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# **6. Model**","metadata":{"papermill":{"duration":0.006,"end_time":"2024-11-26T14:45:12.238551","exception":false,"start_time":"2024-11-26T14:45:12.232551","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport sys\nimport torch\nimport subprocess\n\n# Step 1: Ensure U-2-Net is Cloned\nif not os.path.exists(\"U-2-Net\"):\n    print(\"⏳ Cloning U²-Net repository...\")\n    subprocess.run([\"git\", \"clone\", \"https://github.com/xuebinqin/U-2-Net.git\"])\n    print(\"✅ U²-Net repository cloned!\")\nelse:\n    print(\"✅ U-2-Net is already cloned. Skipping download.\")\n\n# Step 2: Add the correct path for model loading\nsys.path.append(os.path.abspath(\"U-2-Net/model\"))  # Add 'model' folder to Python path\n\n# Step 3: Import the U²-Net Model Correctly\nfrom u2net import U2NET  # Directly import the U2NET class\n\n# Step 4: Initialize U²-Net Model\nmodel = U2NET()\n\n# Step 5: Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Step 6: Load Pretrained Weights from Correct Path\nweights_path = \"/kaggle/working/saved_models/u2net/u2net.pth\"\n\nif os.path.exists(weights_path):\n    print(\"⏳ Loading pretrained U²-Net weights...\")\n    model.load_state_dict(torch.load(weights_path, map_location=device))\n    print(\"✅ U²-Net model loaded successfully with pretrained weights!\")\nelse:\n    print(\"❌ ERROR: Weights file not found! Check the path.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T13:12:19.061727Z","iopub.execute_input":"2025-02-14T13:12:19.062021Z","iopub.status.idle":"2025-02-14T13:12:22.687492Z","shell.execute_reply.started":"2025-02-14T13:12:19.061992Z","shell.execute_reply":"2025-02-14T13:12:22.686679Z"}},"outputs":[{"name":"stdout","text":"⏳ Cloning U²-Net repository...\n✅ U²-Net repository cloned!\n❌ ERROR: Weights file not found! Check the path.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# **7. Loss Function and Metrics**","metadata":{"papermill":{"duration":0.00857,"end_time":"2024-11-26T14:45:13.059587","exception":false,"start_time":"2024-11-26T14:45:13.051017","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define Dice Loss\nclass DiceLoss(nn.Module):\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        inputs = torch.sigmoid(inputs)  # Apply sigmoid to get probabilities\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        intersection = (inputs * targets).sum()\n        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n        return 1 - dice\n\n#Define BCE + Dice Loss\nclass BCEDiceLoss(nn.Module):\n    def __init__(self):\n        super(BCEDiceLoss, self).__init__()\n        self.bce = nn.BCEWithLogitsLoss()\n        self.dice = DiceLoss()\n\n    def forward(self, inputs, targets):\n        bce_loss = self.bce(inputs, targets)\n        dice_loss = self.dice(inputs, targets)\n        return bce_loss + dice_loss","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:22.689993Z","iopub.execute_input":"2025-02-14T13:12:22.690220Z","iopub.status.idle":"2025-02-14T13:12:22.695881Z","shell.execute_reply.started":"2025-02-14T13:12:22.690201Z","shell.execute_reply":"2025-02-14T13:12:22.695075Z"},"papermill":{"duration":0.017112,"end_time":"2024-11-26T14:45:13.083315","exception":false,"start_time":"2024-11-26T14:45:13.066203","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# **8. Training**","metadata":{"papermill":{"duration":0.006556,"end_time":"2024-11-26T14:45:13.09641","exception":false,"start_time":"2024-11-26T14:45:13.089854","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**8.1 Early Stop Definition**","metadata":{"papermill":{"duration":0.006459,"end_time":"2024-11-26T14:45:13.109571","exception":false,"start_time":"2024-11-26T14:45:13.103112","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=5, verbose=False, delta=0):\n        \"\"\"\n        Early stops the training if validation loss doesn't improve after a given patience.\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n        self.delta = delta  # Minimum change to qualify as an improvement\n\n    def __call__(self, val_loss):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif val_loss > self.best_loss - self.delta:\n            self.counter += 1\n            if self.verbose:\n                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_loss = val_loss\n            self.counter = 0\n","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:22.697374Z","iopub.execute_input":"2025-02-14T13:12:22.697713Z","iopub.status.idle":"2025-02-14T13:12:22.717394Z","shell.execute_reply.started":"2025-02-14T13:12:22.697690Z","shell.execute_reply":"2025-02-14T13:12:22.716772Z"},"papermill":{"duration":0.01553,"end_time":"2024-11-26T14:45:13.131629","exception":false,"start_time":"2024-11-26T14:45:13.116099","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"**8.2 Hyperparameters**","metadata":{"papermill":{"duration":0.006918,"end_time":"2024-11-26T14:45:13.145134","exception":false,"start_time":"2024-11-26T14:45:13.138216","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Optimizer\ncriterion = BCEDiceLoss()\noptimizer = torch.optim.AdamW(\n    model.parameters(),  # Ensure 'parameters()' is properly defined\n    lr=6e-4,\n    weight_decay=1e-4\n)\n\n# ReduceLROnPlateau Scheduler\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.5, patience=4, verbose=True, min_lr=1e-6\n)\n\n# Training Parameters\nnum_epochs = 50\nbest_loss = np.inf\nmodel = model.to('cuda')\n\n# Initialize Early Stopping\nearly_stopping = EarlyStopping(patience=5, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:22.718174Z","iopub.execute_input":"2025-02-14T13:12:22.718370Z","iopub.status.idle":"2025-02-14T13:12:22.740466Z","shell.execute_reply.started":"2025-02-14T13:12:22.718354Z","shell.execute_reply":"2025-02-14T13:12:22.739752Z"},"papermill":{"duration":0.330135,"end_time":"2024-11-26T14:45:13.481989","exception":false,"start_time":"2024-11-26T14:45:13.151854","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Move model to GPU \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:22.741166Z","iopub.execute_input":"2025-02-14T13:12:22.741374Z","iopub.status.idle":"2025-02-14T13:12:22.763178Z","shell.execute_reply.started":"2025-02-14T13:12:22.741356Z","shell.execute_reply":"2025-02-14T13:12:22.762368Z"},"papermill":{"duration":0.013992,"end_time":"2024-11-26T14:45:13.503235","exception":false,"start_time":"2024-11-26T14:45:13.489243","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"**8.3 Training Loop**","metadata":{"papermill":{"duration":0.006555,"end_time":"2024-11-26T14:45:13.516379","exception":false,"start_time":"2024-11-26T14:45:13.509824","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n        for images, masks in train_loader:\n            images = images.to('cuda')\n            masks = masks.to('cuda')\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, masks)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            pbar.set_postfix({'loss': loss.item()})\n            pbar.update(1)\n    avg_train_loss = train_loss / len(train_loader)\n\n    # Validation\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for images, masks in val_loader:\n            images = images.to('cuda')\n            masks = masks.to('cuda')\n            outputs = model(images)\n            loss = criterion(outputs, masks)\n            val_loss += loss.item()\n    avg_val_loss = val_loss / len(val_loader)\n\n    # Scheduler step\n    scheduler.step(avg_val_loss)\n\n    # Evaluate \n    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n\n    # Save the model if validation loss has decreased\n    if avg_val_loss < best_loss:\n        best_loss = avg_val_loss\n        torch.save(model.state_dict(), 'best_model.pth')\n        print('Validation loss decreased. Model saved!')\n\n    # Check early stopping\n    early_stopping(avg_val_loss)\n    if early_stopping.early_stop:\n        print('Early stopping triggered. Stopping training.')\n        break","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:14:22.389252Z","iopub.execute_input":"2025-02-14T13:14:22.389641Z","iopub.status.idle":"2025-02-14T13:14:23.343434Z","shell.execute_reply.started":"2025-02-14T13:14:22.389611Z","shell.execute_reply":"2025-02-14T13:14:23.342274Z"},"papermill":{"duration":22303.353045,"end_time":"2024-11-26T20:56:56.875954","exception":false,"start_time":"2024-11-26T14:45:13.522909","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"Epoch 1/50:   0%|          | 0/2465 [00:00<?, ?batch/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-f91b94d9cf88>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure masks are in `long()` format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-b2435e93ce5f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mbce_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mdice_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbce_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdice_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         return F.binary_cross_entropy_with_logits(\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3624\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0;34mf\"Target size ({target.size()}) must be the same as input size ({input.size()})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         )\n","\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([2, 416, 608])) must be the same as input size (torch.Size([2, 1, 416, 608]))"],"ename":"ValueError","evalue":"Target size (torch.Size([2, 416, 608])) must be the same as input size (torch.Size([2, 1, 416, 608]))","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"# Define the path to your saved model state dictionary\n#model_path = '/kaggle/input/best_model1/pytorch/default/1/best_model.pth'\n\n# Initialize the model with the same architecture and settings\n#model = smp.Unet(\n#    encoder_name=\"efficientnet-b1\",        # Same encoder (ResNet34)\n#    encoder_weights=\"imagenet\",     # Same pre-trained weights\n#    in_channels=3,                  # Input channels (RGB)\n#    classes=4                   \n#)\n\n# Load the model state dictionary safely with `weights_only=True`\n#state_dict = torch.load(model_path, map_location='cpu', weights_only=True)\n#model.load_state_dict(state_dict)\n\n# Move model to GPU if available\n#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:24.318822Z","iopub.status.idle":"2025-02-14T13:12:24.319226Z","shell.execute_reply":"2025-02-14T13:12:24.319053Z"},"papermill":{"duration":1.916996,"end_time":"2024-11-26T20:57:00.662991","exception":false,"start_time":"2024-11-26T20:56:58.745995","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **9. Thresholds**","metadata":{"papermill":{"duration":1.90462,"end_time":"2024-11-26T20:57:04.401896","exception":false,"start_time":"2024-11-26T20:57:02.497276","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**Understanding Label and Pixel Thresholds**\nBefore we proceed, let's clarify what we mean by label thresholds and pixel thresholds in this context:\n\n**Label Thresholds:** These thresholds are used to decide whether a particular class (cloud type) is present in the image at all. If the maximum probability for a class is below its label threshold, we consider that the class is not present, and we skip generating a mask for it.\n\n**Pixel Thresholds:** These thresholds are used to binarize the predicted probability maps for each class into binary masks. Pixels with probabilities above the pixel threshold are considered part of the mask; otherwise, they're considered background.","metadata":{"papermill":{"duration":1.947889,"end_time":"2024-11-26T20:57:08.175752","exception":false,"start_time":"2024-11-26T20:57:06.227863","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define thresholds\ninitial_label_thresholds = [0.8, 0.8, 0.8, 0.8]\ninitial_pixel_thresholds = [0.2, 0.4, 0.4, 0.3]\n\nefe_label_thresholds = [0.85, 0.92, 0.85, 0.85]\nefe_pixel_thresholds = [0.21, 0.44, 0.4, 0.4]\n\n# Load the best model\nmodel.load_state_dict(torch.load('best_model.pth'))\nmodel = model.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:24.320166Z","iopub.status.idle":"2025-02-14T13:12:24.320567Z","shell.execute_reply":"2025-02-14T13:12:24.320379Z"},"papermill":{"duration":2.018595,"end_time":"2024-11-26T20:57:12.094605","exception":false,"start_time":"2024-11-26T20:57:10.07601","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **10. Define Metrics & Evaluate**","metadata":{"papermill":{"duration":1.899642,"end_time":"2024-11-26T20:57:15.836939","exception":false,"start_time":"2024-11-26T20:57:13.937297","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**10.1 Define Metrics**","metadata":{"papermill":{"duration":1.952906,"end_time":"2024-11-26T20:57:19.678021","exception":false,"start_time":"2024-11-26T20:57:17.725115","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef dice_coef_metric(y_pred, y_true, smooth=1):\n    '''\n    Calculate Dice Coefficient.\n\n    Parameters:\n    y_pred (numpy.array): Predicted mask.\n    y_true (numpy.array): True mask.\n\n    Returns:\n    float: Dice coefficient.\n    '''\n    y_pred_f = y_pred.flatten()\n    y_true_f = y_true.flatten()\n    intersection = np.sum(y_pred_f * y_true_f)\n    dice = (2. * intersection + smooth) / (np.sum(y_pred_f) + np.sum(y_true_f) + smooth)\n    return dice\n\ndef iou_metric(y_pred, y_true, smooth=1):\n    '''\n    Calculate Intersection over Union (IoU).\n\n    Parameters:\n    y_pred (numpy.array): Predicted mask.\n    y_true (numpy.array): True mask.\n\n    Returns:\n    float: IoU score.\n    '''\n    y_pred_f = y_pred.flatten()\n    y_true_f = y_true.flatten()\n    intersection = np.sum(y_pred_f * y_true_f)\n    union = np.sum(y_pred_f) + np.sum(y_true_f) - intersection\n    iou = (intersection + smooth) / (union + smooth)\n    return iou","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:24.321174Z","iopub.status.idle":"2025-02-14T13:12:24.321581Z","shell.execute_reply":"2025-02-14T13:12:24.321391Z"},"papermill":{"duration":1.911046,"end_time":"2024-11-26T20:57:23.455478","exception":false,"start_time":"2024-11-26T20:57:21.544432","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**10.2 Evaluate Model**","metadata":{"papermill":{"duration":1.913312,"end_time":"2024-11-26T20:57:27.226337","exception":false,"start_time":"2024-11-26T20:57:25.313025","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def evaluate(model, loader, label_thresholds, pixel_thresholds):\n    model.eval()\n    num_classes = 4\n    dice_scores = []\n    iou_scores = []\n    \n    with torch.no_grad():\n        for images, masks in loader:\n            images = images.to('cuda')\n            masks = masks.to('cuda')\n            outputs = model(images)\n            outputs = torch.sigmoid(outputs)\n            preds = outputs.cpu().numpy()\n            trues = masks.cpu().numpy()\n            batch_size = preds.shape[0]\n            \n            # Apply thresholds and calculate metrics\n            for i in range(batch_size):\n                pred = preds[i]\n                true = trues[i]\n                dice = []\n                iou = []\n                for ch in range(num_classes):\n                    pred_mask = pred[ch]\n                    true_mask = true[ch]\n                    \n                    # Apply label threshold\n                    max_prob = pred_mask.max()\n                    if max_prob < label_thresholds[ch]:\n                        # If max probability is below label threshold, consider class absent\n                        pred_mask = np.zeros_like(pred_mask)\n                    else:\n                        # Apply pixel threshold\n                        pred_mask = (pred_mask > pixel_thresholds[ch]).astype(np.uint8)\n                    \n                    # Calculate Dice coefficient\n                    intersection = np.logical_and(pred_mask, true_mask).sum()\n                    total = pred_mask.sum() + true_mask.sum()\n                    dice_score = (2 * intersection + 1e-7) / (total + 1e-7)\n                    dice.append(dice_score)\n                    \n                    # Calculate IoU\n                    union = pred_mask.sum() + true_mask.sum() - intersection\n                    iou_score = (intersection + 1e-7) / (union + 1e-7)\n                    iou.append(iou_score)\n                    \n                dice_scores.append(dice)\n                iou_scores.append(iou)\n                \n    # Convert lists to numpy arrays\n    dice_scores = np.array(dice_scores)\n    iou_scores = np.array(iou_scores)\n    \n    # Calculate mean scores per class\n    mean_dice_per_class = np.mean(dice_scores, axis=0)\n    mean_iou_per_class = np.mean(iou_scores, axis=0)\n    \n    # Calculate overall mean scores\n    mean_dice = np.mean(mean_dice_per_class)\n    mean_iou = np.mean(mean_iou_per_class)\n    \n    return mean_dice_per_class, mean_dice, mean_iou_per_class, mean_iou\n","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:24.322363Z","iopub.status.idle":"2025-02-14T13:12:24.322767Z","shell.execute_reply":"2025-02-14T13:12:24.322592Z"},"papermill":{"duration":1.937803,"end_time":"2024-11-26T20:57:31.004654","exception":false,"start_time":"2024-11-26T20:57:29.066851","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model before threshold optimization\nprint(\"Evaluating model before threshold optimization on full validation set...\")\nmean_dice_per_class, mean_dice, mean_iou_per_class, mean_iou = evaluate(\n    model, val_loader, initial_label_thresholds, initial_pixel_thresholds\n)\n\n# Define class labels\nlabels = ['Fish', 'Flower', 'Gravel', 'Sugar']\n\n# Print per-class Dice and IoU\nfor idx, label in enumerate(labels):\n    print(f'{label} - Dice: {mean_dice_per_class[idx]:.4f}, IoU: {mean_iou_per_class[idx]:.4f}')\n\n# Print overall mean Dice and IoU\nprint(f'Overall Mean Dice: {mean_dice:.4f}')\nprint(f'Overall Mean IoU: {mean_iou:.4f}')","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:24.323588Z","iopub.status.idle":"2025-02-14T13:12:24.323986Z","shell.execute_reply":"2025-02-14T13:12:24.323870Z"},"papermill":{"duration":34.90098,"end_time":"2024-11-26T20:58:07.745262","exception":false,"start_time":"2024-11-26T20:57:32.844282","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **11. Threshold Optimization**","metadata":{"papermill":{"duration":1.887546,"end_time":"2024-11-26T20:58:11.465442","exception":false,"start_time":"2024-11-26T20:58:09.577896","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**note: this takes too long :D**","metadata":{"papermill":{"duration":1.876194,"end_time":"2024-11-26T20:58:15.172173","exception":false,"start_time":"2024-11-26T20:58:13.295979","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# def optimize_thresholds(model, loader, initial_label_thresholds, initial_pixel_thresholds):\n#     best_label_thresholds = initial_label_thresholds.copy()\n#     best_pixel_thresholds = initial_pixel_thresholds.copy()\n#     best_dice_scores = np.zeros(4)\n#     best_iou_scores = np.zeros(4)\n    \n#     # Define threshold ranges\n#     label_threshold_ranges = [np.linspace(0.84, 0.93, 10) for _ in range(4)]\n#     pixel_threshold_ranges = [np.linspace(0.2, 0.5, 10) for _ in range(4)]\n    \n#     # Optimize label thresholds\n#     print(\"Optimizing label thresholds...\")\n#     for idx in range(4):\n#         best_dice_score = 0\n#         best_iou_score = 0\n#         for t in label_threshold_ranges[idx]:\n#             temp_label_thresholds = best_label_thresholds.copy()\n#             temp_label_thresholds[idx] = t\n#             mean_dice_per_class, mean_dice, mean_iou_per_class, mean_iou = evaluate(\n#                 model, loader, temp_label_thresholds, best_pixel_thresholds\n#             )\n#             # Update if better Dice score is achieved\n#             if mean_dice > best_dice_score:\n#                 best_dice_score = mean_dice\n#                 best_iou_score = mean_iou\n#                 best_label_thresholds[idx] = t\n#                 best_dice_scores[idx] = mean_dice\n#                 best_iou_scores[idx] = mean_iou\n#         print(f'Best label threshold for class {idx}: {best_label_thresholds[idx]}, '\n#               f'Dice: {best_dice_scores[idx]:.4f}, IoU: {best_iou_scores[idx]:.4f}')\n    \n#     # Optimize pixel thresholds\n#     print(\"Optimizing pixel thresholds...\")\n#     for idx in range(4):\n#         best_dice_score = 0\n#         best_iou_score = 0\n#         for t in pixel_threshold_ranges[idx]:\n#             temp_pixel_thresholds = best_pixel_thresholds.copy()\n#             temp_pixel_thresholds[idx] = t\n#             mean_dice_per_class, mean_dice, mean_iou_per_class, mean_iou = evaluate(\n#                 model, loader, best_label_thresholds, temp_pixel_thresholds\n#             )\n#             # Update if better Dice score is achieved\n#             if mean_dice > best_dice_score:\n#                 best_dice_score = mean_dice\n#                 best_iou_score = mean_iou\n#                 best_pixel_thresholds[idx] = t\n#                 best_dice_scores[idx] = mean_dice\n#                 best_iou_scores[idx] = mean_iou\n#         print(f'Best pixel threshold for class {idx}: {best_pixel_thresholds[idx]}, '\n#               f'Dice: {best_dice_scores[idx]:.4f}, IoU: {best_iou_scores[idx]:.4f}')\n    \n#     return best_label_thresholds, best_pixel_thresholds\n\n# # Optimize thresholds on the full validation set\n# best_label_thresholds, best_pixel_thresholds = optimize_thresholds(\n#     model, val_loader, initial_label_thresholds, initial_pixel_thresholds\n# )\n\n# print('Optimized label thresholds:', best_label_thresholds)\n# print('Optimized pixel thresholds:', best_pixel_thresholds)\n","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:24.324830Z","iopub.status.idle":"2025-02-14T13:12:24.325084Z","shell.execute_reply":"2025-02-14T13:12:24.324982Z"},"papermill":{"duration":1953.810094,"end_time":"2024-11-26T21:30:50.850213","exception":false,"start_time":"2024-11-26T20:58:17.040119","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **12. Submission**","metadata":{"papermill":{"duration":1.867002,"end_time":"2024-11-26T21:30:54.525671","exception":false,"start_time":"2024-11-26T21:30:52.658669","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def mask2rle(mask):\n    '''\n    Convert mask to RLE.\n    mask: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = mask.flatten(order='F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    rle = ' '.join(str(x) for x in runs)\n    return rle\n\ndef create_submission(model, label_thresholds, pixel_thresholds, submission_file='submission.csv'):\n    test_images = os.listdir(test_img_dir)\n    results = []\n    model.eval()\n    with torch.no_grad():\n        for img_name in tqdm(test_images):\n            # Load image\n            img_path = os.path.join(test_img_dir, img_name)\n            image = cv2.imread(img_path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            # Resize\n            image = cv2.resize(image, (608, 416))\n            image = image.transpose(2, 0, 1).astype(np.float32) / 255.0\n            image = torch.tensor(image).unsqueeze(0).to('cuda')\n            # Predict\n            output = model(image)\n            output = torch.sigmoid(output).cpu().numpy()[0]\n            # Initialize empty list for masks\n            masks = []\n            labels = ['Fish', 'Flower', 'Gravel', 'Sugar']\n            for ch in range(4):\n                pred_mask = output[ch]\n                # Apply label threshold\n                max_prob = pred_mask.max()\n                if max_prob < label_thresholds[ch]:\n                    # If max probability is below label threshold, consider class absent\n                    pred_mask = np.zeros_like(pred_mask)\n                else:\n                    # Apply pixel threshold\n                    pred_mask = (pred_mask > pixel_thresholds[ch]).astype(np.uint8)\n                # Resize to 350x525\n                pred_mask = cv2.resize(pred_mask, (525, 350))\n                masks.append(pred_mask)\n            # Convert masks to RLE\n            for i, label in enumerate(labels):\n                pred_mask = masks[i]\n                if pred_mask.sum() == 0:\n                    rle = ''\n                else:\n                    rle = mask2rle(pred_mask)\n                results.append({'Image_Label': f'{img_name}_{label}', 'EncodedPixels': rle})\n    submission_df = pd.DataFrame(results)\n    # Fill missing EncodedPixels with empty strings\n    submission_df['EncodedPixels'] = submission_df['EncodedPixels'].fillna('')\n    submission_df.to_csv(submission_file, index=False)\n    print('Submission file created!')\n","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:24.325722Z","iopub.status.idle":"2025-02-14T13:12:24.325988Z","shell.execute_reply":"2025-02-14T13:12:24.325882Z"},"papermill":{"duration":1.953879,"end_time":"2024-11-26T21:30:58.28557","exception":false,"start_time":"2024-11-26T21:30:56.331691","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create submission\ncreate_submission(model, initial_label_thresholds, initial_pixel_thresholds, submission_file='submission1.csv')","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:24.326706Z","iopub.status.idle":"2025-02-14T13:12:24.327018Z","shell.execute_reply":"2025-02-14T13:12:24.326861Z"},"papermill":{"duration":352.987739,"end_time":"2024-11-26T21:36:53.072409","exception":false,"start_time":"2024-11-26T21:31:00.08467","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Create submission\n# create_submission(model, best_label_thresholds, best_pixel_thresholds, submission_file='submission2.csv')","metadata":{"execution":{"iopub.status.busy":"2025-02-14T13:12:24.327837Z","iopub.status.idle":"2025-02-14T13:12:24.328082Z","shell.execute_reply":"2025-02-14T13:12:24.327982Z"},"papermill":{"duration":271.447022,"end_time":"2024-11-26T21:41:30.633192","exception":false,"start_time":"2024-11-26T21:36:59.18617","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create efe\ncreate_submission(model, efe_label_thresholds, efe_pixel_thresholds, submission_file='submission3.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T13:12:24.328989Z","iopub.status.idle":"2025-02-14T13:12:24.329277Z","shell.execute_reply":"2025-02-14T13:12:24.329153Z"}},"outputs":[],"execution_count":null}]}